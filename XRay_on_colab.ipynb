{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XRay_on_colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cjIFrxl4xpb",
        "colab_type": "text"
      },
      "source": [
        "# X-Ray Landmark Detection on Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYcltK7e6r5A",
        "colab_type": "text"
      },
      "source": [
        "## Preperation\n",
        "\n",
        "### Imports and installation of the required libraries\n",
        "\n",
        "The libraries tensorboardx and bayesian-optimization are not within the virtual environment of Google Colab, hence they have to be installed manually."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI-mX3ic4zBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from zipfile import ZipFile\n",
        "import os, glob\n",
        "\n",
        "! pip install tensorboardx\n",
        "! pip install bayesian-optimization\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo5Rut3WcSHH",
        "colab_type": "text"
      },
      "source": [
        "### Google Colab or Zip upload\n",
        "Either upload your project to Google Drive and mount it or upload project manually as .zip file and extract it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBFA_7f5cUe0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_google_drive = True\n",
        "\n",
        "if use_google_drive:\n",
        "  drive.mount('gdrive')\n",
        "  % cd gdrive/My\\ Drive/MLMI_SS19\n",
        "else:\n",
        "  file = files.upload()\n",
        "  file_path = os.path.join(ROOT,list(file.keys())[0])\n",
        "  zip_file = ZipFile(file_path)\n",
        "  zip_file.extractall(ROOT)\n",
        "  zip_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRn8HOi7rSvV",
        "colab_type": "text"
      },
      "source": [
        "### Tensorboard and tunneling\n",
        "Install ngrok for tunneling "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc71w6qerQtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if os.path.exists(\"ngrok-stable-linux-amd64.zip\"):\n",
        "  os.remove(\"ngrok-stable-linux-amd64.zip\")\n",
        "\n",
        "if os.path.exists(\"ngrok\"):\n",
        "  os.remove(\"ngrok\")\n",
        "  \n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ6JZY18fS4G",
        "colab_type": "text"
      },
      "source": [
        "Start tensorboard and forward port with ngrok"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kele9MJBfAVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = 'saved/log/'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fGr1nvVqduU",
        "colab_type": "text"
      },
      "source": [
        "Extract ngrok url for accessing tensorboard\n",
        "\n",
        "**Attention**: Sometimes it throws an error like this:\n",
        "```\n",
        "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
        "```\n",
        "If this is the case the easiest way to solve this issue is to delete the ngrok*.zip and ngrok from the Google Drive folder and install them again.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOJxnfekqPg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8QsqbYA53MI",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "\n",
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1xgAd-K4Q30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from config import CONFIG  \n",
        "from parse_config import ConfigParser\n",
        "from train import main"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsplbjDNM_eF",
        "colab_type": "text"
      },
      "source": [
        "### Handle IOError\n",
        "\n",
        "Google Colab has problems dealing with large amount of elements within a folder. Running it until it successfully loads will ensure there won't be an error later on. See [here](https://research.google.com/colaboratory/faq.html#drive-timeout) for further details.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEc0CEqcQ2OW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_folder = 'SubsetOnePatient' # 'OnePatient'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ1FzHqKLZU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "while True:\n",
        "  try:\n",
        "    os.listdir(f'data/XRay/{data_folder}/Training/ABD_LYMPH_005')\n",
        "    os.listdir(f'data/XRay/{data_folder}/Validation/ABD_LYMPH_005')\n",
        "  except IOError:\n",
        "    print('IOError - keep running')\n",
        "  else:\n",
        "    print('succesfully accessed files')\n",
        "    break;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L41jcwBrqkev",
        "colab_type": "text"
      },
      "source": [
        "### Manual Training\n",
        "Modify parameters and train model **manually**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hSLJkNjMZI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CONFIG['arch']['args']['x_channels'] = 128\n",
        "CONFIG['arch']['args']['stage_channels'] = 512\n",
        "CONFIG['arch']['args']['num_stages'] = 5\n",
        "CONFIG['arch']['args']['dilation'] = 1 #1, 2, 4\n",
        "CONFIG['arch']['args']['depthwise_separable_convolution'] = False\n",
        "CONFIG['arch']['args']['squeeze_excitation'] = False\n",
        "\n",
        "\n",
        "CONFIG['data_loader']['args']['data_dir'] = f'data/XRay/{data_folder}'\n",
        "CONFIG['data_loader']['args']['batch_size'] = 1\n",
        "CONFIG['data_loader']['args']['validation_split'] = 0.1\n",
        "CONFIG['data_loader']['args']['shuffle'] = False\n",
        "CONFIG['data_loader']['args']['custom_args']['fraction_of_dataset'] = 1\n",
        "CONFIG['data_loader']['args']['custom_args']['sigma'] = 80\n",
        "CONFIG['data_loader']['args']['custom_args']['sigma_reduction_factor'] = 1\n",
        "CONFIG['data_loader']['args']['custom_args']['sigma_reduction_factor_change_rate'] = 0\n",
        "\n",
        "CONFIG['optimizer']['args']['lr'] = 1e-5\n",
        "\n",
        "CONFIG['trainer']['epochs'] = 1000\n",
        "CONFIG['trainer']['save_period'] = 1\n",
        "CONFIG['trainer']['early_stop'] = 10\n",
        "CONFIG['trainer']['keep_only_latest_checkpoint'] = True\n",
        "\n",
        "CONFIG['prediction_blur'] = 1\n",
        "\n",
        "main(ConfigParser(CONFIG))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc_pc9Uht4Yv",
        "colab_type": "text"
      },
      "source": [
        "### Resume training\n",
        "By default it takes your last training run and the last model of it. \n",
        "If you want to use a specific run or a specific model you can provide it like this:\n",
        "\n",
        "```\n",
        "run_dir = \"0629_194146\"\n",
        "model_pth = \"checkpoint-epoch11.pth\"\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69wusrvmt3en",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from importlib.machinery import SourceFileLoader\n",
        "import numpy as np\n",
        "\n",
        "base_saved_dir = \"saved/models/XRay\"\n",
        "\n",
        "run_dir = None\n",
        "model_pth = None\n",
        "\n",
        "for temp_run_dir in os.listdir(base_saved_dir)[::-1]:\n",
        "  if run_dir is None:\n",
        "      run_path = os.path.join(base_saved_dir, temp_run_dir)\n",
        "  else:\n",
        "    run_path = os.path.join(base_saved_dir, run_dir)\n",
        "\n",
        "  if model_pth is None:\n",
        "    model_path_list = glob.glob(f'{run_path}/checkpoint-epoch*.pth')\n",
        "    if not model_path_list:\n",
        "      continue\n",
        "    model_path = model_path_list[-1]\n",
        "    break\n",
        "  else:\n",
        "    model_path = os.path.join(run_path, model_pth)\n",
        "    break\n",
        "\n",
        "config = SourceFileLoader(\"CONFIG\", os.path.join(run_path, 'config.py')).load_module().CONFIG\n",
        "main(ConfigParser(config, model_path))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7vyQPQ5Q8aa",
        "colab_type": "text"
      },
      "source": [
        "### Bayesian Optimization\n",
        "Do **automatic** Bayesian optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO9SmoL7pFaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bayes_opt_train import run_bayes_opt\n",
        "\n",
        "run_bayes_opt({\n",
        "    \n",
        "\n",
        "}, init_points=10, n_iter=10)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}